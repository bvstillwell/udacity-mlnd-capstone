{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just remember.... Start with the simplist model, and add features\n",
    "## Features\n",
    "- Daily returns\n",
    " - daily_returns[t] = (price[t]/price[-1])-1\n",
    "\n",
    "## Predictions\n",
    "1. Will the price stay the same or go up tomorrow. up=1, others=0\n",
    "\n",
    "## Things I want to find out\n",
    "- Can we predict gold resonably well\n",
    "    - What features are corrrelated?\n",
    "    - What are good features?\n",
    "    - Do we need lots of them?\n",
    "- Has trading changed in modern times\n",
    "    - Has automated trading made things different?\n",
    "    - Do we overfit if we only look at old data?\n",
    "    - Was old data correlated to different features that are no longer important?\n",
    "       \n",
    "## New quesitions\n",
    "- Do the dates work correctly?\n",
    " - Asuming the day is correct, we use\n",
    " - UK Gold 10:30am (GMT)\n",
    " - UK Gold 3pm (GMT)\n",
    " - FX NYC 12pm (4pm GMT)\n",
    "  - http://www.federalreserve.gov/pubs/bulletin/2005/winter05_index.pdf\n",
    "\n",
    "- Score seems kind of high, why?\n",
    "- Is the model accurate today?\n",
    "    - Let's test on the data from the last year\n",
    "\n",
    "- How long is a model valid before it's predictions don't work?\n",
    "\n",
    "- Can the model predict further out?\n",
    "\n",
    "- Are they correct if we retrain every day?\n",
    "\n",
    "- Can we predict bigger changes rather than just positive?\n",
    "\n",
    "## Notes discovered\n",
    "We are only predicting gold against USD. What about the global economy? Do we use a bag of currencies? What are their weightings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GridSearchCV',\n",
       " 'KFold',\n",
       " '__builtins__',\n",
       " '__file__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " 'calc_daily_ret',\n",
       " 'calc_rolling_averages',\n",
       " 'create_y_labels',\n",
       " 'currencies',\n",
       " 'datetime',\n",
       " 'download_quandl',\n",
       " 'draw_info',\n",
       " 'ld',\n",
       " 'li',\n",
       " 'load_and_calculate',\n",
       " 'load_and_prepare_data',\n",
       " 'logger',\n",
       " 'logging',\n",
       " 'os',\n",
       " 'pd',\n",
       " 'plt',\n",
       " 'predict_and_score',\n",
       " 'quandl',\n",
       " 're',\n",
       " 'set_date_range',\n",
       " 'test_train']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import helper1 as hlp\n",
    "dir(hlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Kept here incase I need some of this later\n",
    "\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# import numpy as np\n",
    "\n",
    "# def rolling_linear_regression(df, n, col):\n",
    "#     def func(indexes, df): \n",
    "#         d_tmp = df.loc[indexes]\n",
    "                \n",
    "#         X = np.array(range(len(indexes))).reshape([-1, 1])\n",
    "#         y = d_tmp[col].reshape([-1, 1])\n",
    "        \n",
    "#         lr.fit(X, y)\n",
    "#         result = lr.coef_\n",
    "        \n",
    "#         return result\n",
    "    \n",
    "#     lr = LinearRegression()\n",
    "#     result = pd.rolling_apply(df.index.values, n, lambda i: func(i, df))\n",
    "#     return result\n",
    "\n",
    "# def rate_of_change(df, n, col):\n",
    "#     prev = df.shift(n)[col]\n",
    "#     result = 100 * (df[col] - prev) / prev\n",
    "#     return result\n",
    "\n",
    "# def roc_ratio(df, n, col):\n",
    "#     prev = df.shift(n)[col]\n",
    "    \n",
    "    \n",
    "# for n in [5, 10, 20]:\n",
    "#     df['lr_%s' % n] = rolling_linear_regression(df, n, 'v')\n",
    "#     df['roc_%s' % n] = rate_of_change(df, n, 'v')\n",
    "\n",
    "# df['v'].plot()\n",
    "# df[['lr_%s' % n for n in [5, 10, 20]]].plot()\n",
    "# df[['roc_%s' % n for n in [5, 10, 20]]].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets see how it works for the last year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Load currencies\n",
      "INFO:root:Loading file:currencies\n",
      "INFO:root:Are we using the correct timezone?\n",
      "INFO:root:inverse currencies so they are all 'how many x does 1 usd buy'\n",
      "INFO:root:Lets get the gold\n",
      "INFO:root:Loading file:LBMA_GOLD\n",
      "INFO:root:Forward fill weekends and holidays\n",
      "INFO:root:Set date range Dates\n",
      "INFO:root:Using aa 15 year period of data\n",
      "INFO:root:calculate daily returns\n",
      "INFO:root:caluclate rolling averages\n",
      "INFO:root:Index([u'GOLD_dr', u'JPY_dr', u'AUD_dr', u'GBP_dr', u'NZD_dr', u'CNY_dr',\n",
      "       u'CAD_dr', u'CHF_dr', u'EUR_dr', u'GOLD_dr_2', u'JPY_dr_2', u'AUD_dr_2',\n",
      "       u'GBP_dr_2', u'NZD_dr_2', u'CNY_dr_2', u'CAD_dr_2', u'CHF_dr_2',\n",
      "       u'EUR_dr_2', u'GOLD_dr_7', u'JPY_dr_7', u'AUD_dr_7', u'GBP_dr_7',\n",
      "       u'NZD_dr_7', u'CNY_dr_7', u'CAD_dr_7', u'CHF_dr_7', u'EUR_dr_7',\n",
      "       u'GOLD_dr_30', u'JPY_dr_30', u'AUD_dr_30', u'GBP_dr_30', u'NZD_dr_30',\n",
      "       u'CNY_dr_30', u'CAD_dr_30', u'CHF_dr_30', u'EUR_dr_30', u'GOLD_dr_180',\n",
      "       u'JPY_dr_180', u'AUD_dr_180', u'GBP_dr_180', u'NZD_dr_180',\n",
      "       u'CNY_dr_180', u'CAD_dr_180', u'CHF_dr_180', u'EUR_dr_180'],\n",
      "      dtype='object')\n",
      "INFO:root:Create the y labels vector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3658, 45)\n",
      "(3658,)\n",
      "2    1861\n",
      "1    1797\n",
      "Name: GOLD_dr, dtype: int64\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Actual\n",
      "INFO:root:0.688172043011\n",
      "INFO:root:             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.59      0.82      0.69        39\n",
      "        2.0       0.46      0.21      0.29        28\n",
      "\n",
      "avg / total       0.54      0.57      0.52        67\n",
      "\n",
      "INFO:root:random sample\n",
      "INFO:root:0.564102564103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(array([ 1.,  2.]), array([54, 13]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.68817204301075263"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run(X, y, train_start, train_end, test_start, test_end):    \n",
    "    # Get data for training\n",
    "    X_train = X[train_start: train_end]\n",
    "    y_train = y[train_start: train_end]\n",
    "    \n",
    "    print X_train.shape\n",
    "    print y_train.shape\n",
    "    print y_train.value_counts()\n",
    "\n",
    "    param_grid={\n",
    "        'kernel': ['linear'],\n",
    "    }\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.grid_search import GridSearchCV\n",
    "#     clf = SVC()\n",
    "#     best_clf = hlp.test_train(X_train, y_train, clf, param_grid)\n",
    "    #print y_train\n",
    "    \n",
    "    param_grid={\n",
    "        'max_depth': range(2,5) + [10, 15],\n",
    "        'min_samples_split' : [2,10,20]\n",
    "    }\n",
    "    clf = DecisionTreeClassifier()\n",
    "    gs = GridSearchCV(clf, param_grid)\n",
    "    gs.fit(X_train, y_train)\n",
    "    clf = gs.best_estimator_\n",
    "\n",
    "    # Get data for testing\n",
    "    X_test = X[test_start: test_end]\n",
    "    y_test = y[test_start: test_end]\n",
    "    \n",
    "    from sklearn.metrics import f1_score\n",
    "    from sklearn.metrics import classification_report\n",
    "    \n",
    "    print clf\n",
    "    pred_actual = clf.predict(X_test)\n",
    "    print np.unique(pred_actual, return_counts=True)    \n",
    "    logging.info(\"Actual\")\n",
    "    score = f1_score(y_test, pred_actual)\n",
    "    logging.info(score)\n",
    "    logging.info(classification_report(y_test, pred_actual))\n",
    "    \n",
    "    logging.info(\"random sample\")\n",
    "    pred_sample = y_test.sample(y_test.shape[0])\n",
    "    logging.info(f1_score(y_test, pred_sample))\n",
    "    return score\n",
    "    \n",
    "import numpy as np\n",
    "data_start = '2001-01-04'\n",
    "data_end = '2016-01-04'\n",
    "\n",
    "X = hlp.load_and_calculate()\n",
    "hlp.li(X.columns)\n",
    "\n",
    "y = hlp.create_y_labels(X['GOLD_dr'], days_ahead=2)\n",
    "\n",
    "import pandas as pd\n",
    "#print pd.concat([X['GOLD_dr'], X['GOLD_dr'].shift(1), X['GOLD_dr'].shift(2)], axis=1)\n",
    "\n",
    "# cols = X.columns.values\n",
    "# for col in cols:\n",
    "#     if \"GOLD_\" in col:\n",
    "#         X.drop(col, axis=1, inplace=True)\n",
    "\n",
    "#run(X, y, '2001-01-04', '2011-01-04','2011-01-04', '2016-01-04')\n",
    "run(X, y, '2001-04-01', '2015-06-01','2015-06-01', '2015-09-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:1\n",
      "INFO:root:Create the y labels vector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3101, 45)\n",
      "(3101,)\n",
      "2    1604\n",
      "1    1497\n",
      "Name: GOLD_dr, dtype: int64\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Actual\n",
      "INFO:root:0.490106544901\n",
      "INFO:root:             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.60      0.41      0.49       390\n",
      "        2.0       0.48      0.67      0.56       321\n",
      "\n",
      "avg / total       0.55      0.53      0.52       711\n",
      "\n",
      "INFO:root:random sample\n",
      "INFO:root:0.551282051282\n",
      "INFO:root:2\n",
      "INFO:root:Create the y labels vector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(array([ 1.,  2.]), array([267, 444]))\n",
      "(3101, 45)\n",
      "(3101,)\n",
      "2    1604\n",
      "1    1497\n",
      "Name: GOLD_dr, dtype: int64\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Actual\n",
      "INFO:root:0.383045525903\n",
      "INFO:root:             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.49      0.31      0.38       390\n",
      "        2.0       0.42      0.61      0.50       321\n",
      "\n",
      "avg / total       0.46      0.45      0.44       711\n",
      "\n",
      "INFO:root:random sample\n",
      "INFO:root:0.54358974359\n",
      "INFO:root:30\n",
      "INFO:root:Create the y labels vector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(array([ 1.,  2.]), array([247, 464]))\n",
      "(3101, 45)\n",
      "(3101,)\n",
      "2    1603\n",
      "1    1498\n",
      "Name: GOLD_dr, dtype: int64\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=10, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Actual\n",
      "INFO:root:0.574233128834\n",
      "INFO:root:             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.57      0.58      0.57       404\n",
      "        2.0       0.43      0.42      0.43       307\n",
      "\n",
      "avg / total       0.51      0.51      0.51       711\n",
      "\n",
      "INFO:root:random sample\n",
      "INFO:root:0.596534653465\n",
      "INFO:root:60\n",
      "INFO:root:Create the y labels vector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(array([ 1.,  2.]), array([411, 300]))\n",
      "(3101, 45)\n",
      "(3101,)\n",
      "2    1601\n",
      "1    1500\n",
      "Name: GOLD_dr, dtype: int64\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Actual\n",
      "INFO:root:0.633684210526\n",
      "INFO:root:             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.56      0.72      0.63       417\n",
      "        2.0       0.35      0.21      0.26       294\n",
      "\n",
      "avg / total       0.48      0.51      0.48       711\n",
      "\n",
      "INFO:root:random sample\n",
      "INFO:root:0.592326139089\n",
      "INFO:root:90\n",
      "INFO:root:Create the y labels vector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(array([ 1.,  2.]), array([533, 178]))\n",
      "(3101, 45)\n",
      "(3101,)\n",
      "2    1605\n",
      "1    1496\n",
      "Name: GOLD_dr, dtype: int64\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=15,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Actual\n",
      "INFO:root:0.490984743412\n",
      "INFO:root:             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.62      0.41      0.49       435\n",
      "        2.0       0.39      0.61      0.48       276\n",
      "\n",
      "avg / total       0.53      0.48      0.49       711\n",
      "\n",
      "INFO:root:random sample\n",
      "INFO:root:0.602298850575\n",
      "INFO:root:180\n",
      "INFO:root:Create the y labels vector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(array([ 1.,  2.]), array([286, 425]))\n",
      "(3101, 45)\n",
      "(3101,)\n",
      "2    1598\n",
      "1    1503\n",
      "Name: GOLD_dr, dtype: int64\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Actual\n",
      "INFO:root:0.0369609856263\n",
      "INFO:root:             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.56      0.02      0.04       471\n",
      "        2.0       0.34      0.97      0.50       240\n",
      "\n",
      "avg / total       0.49      0.34      0.19       711\n",
      "\n",
      "INFO:root:random sample\n",
      "INFO:root:0.632696390658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(array([ 1.,  2.]), array([ 16, 695]))\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i in [1, 2, 30, 60, 90, 180]:\n",
    "    hlp.li(i)\n",
    "    y = hlp.create_y_labels(X['GOLD_dr'], days_ahead=i)\n",
    "    score = run(X, y, '2001-04-01', '2013-04-01','2013-04-01', '2016-04-01')\n",
    "    scores.append(score)\n",
    "\n",
    "# for c in [1, 5, 30, 60]\n",
    "#     y = hlp.create_y_labels(X['GOLD_dr'])\n",
    "#     run(X, y, '2001-01-04', '2011-01-04', '2011-01-04', '2016-01-04')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.49010654490106542,\n",
       " 0.38304552590266872,\n",
       " 0.57423312883435573,\n",
       " 0.63368421052631574,\n",
       " 0.49098474341192783,\n",
       " 0.036960985626283367]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEDCAYAAAAoWo9tAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3857e2b290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "import seaborn as sns\n",
    "sns.barplot(x=range(len(scores)), y=scores)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
