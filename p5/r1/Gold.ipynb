{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just remember.... Start with the simplist model, and add features\n",
    "## Features\n",
    "- Daily returns\n",
    " - daily_returns[t] = (price[t]/price[-1])-1\n",
    "\n",
    "## Predictions\n",
    "1. Will the price stay the same or go up tomorrow. up=1, others=0\n",
    "\n",
    "## Things I want to find out\n",
    "- Can we predict gold resonably well\n",
    "    - What features are corrrelated?\n",
    "    - What are good features?\n",
    "    - Do we need lots of them?\n",
    "- Has trading changed in modern times\n",
    "    - Has automated trading made things different?\n",
    "    - Do we overfit if we only look at old data?\n",
    "    - Was old data correlated to different features that are no longer important?\n",
    "       \n",
    "## New quesitions\n",
    "- Do the dates work correctly?\n",
    " - Asuming the day is correct, we use\n",
    " - UK Gold 10:30am (GMT)\n",
    " - UK Gold 3pm (GMT)\n",
    " - FX NYC 12pm (4pm GMT)\n",
    "  - http://www.federalreserve.gov/pubs/bulletin/2005/winter05_index.pdf\n",
    "\n",
    "- Score seems kind of high, why?\n",
    "- Is the model accurate today?\n",
    "    - Let's test on the data from the last year\n",
    "\n",
    "- How long is a model valid before it's predictions don't work?\n",
    "\n",
    "- Can the model predict further out?\n",
    "\n",
    "- Are they correct if we retrain every day?\n",
    "\n",
    "- Can we predict bigger changes rather than just positive?\n",
    "\n",
    "## Notes discovered\n",
    "We are only predicting gold against USD. What about the global economy? Do we use a bag of currencies? What are their weightings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Log message\n",
    "def lm(text):\n",
    "    print\n",
    "    print text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import quandl\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# import quandl\n",
    "def download_quandl(codes, filename=None, load_file=True):\n",
    "    if filename is None:\n",
    "        filename = re.sub('[^-a-zA-Z0-9_.() ]+', '_', codes)\n",
    "\n",
    "    if load_file and os.path.exists(filename):\n",
    "        lm(\"Loading file:%s\" % filename)\n",
    "        return pd.read_csv(filename)\n",
    "    \n",
    "    the_data = quandl.get(codes)\n",
    "    the_data.describe()\n",
    "    the_data.head()\n",
    "    the_data.to_csv(filename)\n",
    "    return the_data\n",
    "\n",
    "currencies = {\n",
    "#     'AUD': 'FRED/XUDLADD', \n",
    "#     'JPY': 'FRED/XUDLJYD',\n",
    "#     'GBP': 'FRED/XUDLGBD',\n",
    "#     #'EUR': 'FRED/DEXUSEU',\n",
    "#     'EUR': 'FRED/XUDLERG',\n",
    "#     'CAD': 'FRED/XUDLCDD',\n",
    "#     'CHF': 'FRED/XUDLSFD',\n",
    "#     'CNY': 'FRED/XUDLBK73',\n",
    "#     'NZD': 'FRED/XUDLNDD',\n",
    "    \n",
    "    'AUD': 'FRED/DEXUSAL', \n",
    "    'JPY': 'FRED/DEXJPUS',\n",
    "    'GBP': 'FRED/DEXUSUK',\n",
    "    'EUR': 'FRED/DEXUSEU',\n",
    "    'CAD': 'FRED/DEXCAUS',\n",
    "    'CHF': 'FRED/DEXSZUS',\n",
    "    'CNY': 'FRED/DEXCHUS',\n",
    "    'NZD': 'FRED/DEXUSNZ',\n",
    "    }\n",
    "\n",
    "def load_and_prepare_data():\n",
    "    lm(\"Load currencies\")\n",
    "    df_curr = download_quandl([currencies[k] for k in currencies], 'currencies')\n",
    "    print df_curr.head()\n",
    "    #df_curr.describe()\n",
    "    df_curr.set_index('DATE', inplace=True)\n",
    "    df_curr.columns = [a for a in currencies]\n",
    "\n",
    "    lm(\"Are we using the correct timezone?\")\n",
    "    #FRED = noon NYC time\n",
    "    # London 10:30,3pm\n",
    "    # NYC \n",
    "\n",
    "\n",
    "\n",
    "    lm(\"inverse currencies so they are all 'how many x does 1 usd buy'\")\n",
    "    for curr in currencies:\n",
    "        if currencies[curr][:-2] != 'US':\n",
    "            df_curr[curr] = 1. / df_curr[curr]\n",
    "    print df_curr['GBP'][:10]\n",
    "\n",
    "    lm(\"Lets get the gold\")\n",
    "    df_gold = download_quandl(\"LBMA/GOLD\")\n",
    "    print df_gold.head()\n",
    "    df_gold.set_index('Date', inplace=True)\n",
    "    pd.concat([df_gold, df_curr], axis=1)\n",
    "    df_gold.drop([c for c in df_gold.columns.values if c != 'USD (AM)'], axis=1, inplace=True)\n",
    "    df_gold.columns = ['GOLD']\n",
    "\n",
    "    df_concat = pd.concat([df_gold, df_curr], axis=1)\n",
    "\n",
    "    lm(\"Forward fill weekends and holidays\")\n",
    "    print df_concat.isnull().sum()\n",
    "    df_concat.fillna(method='ffill', inplace=True)\n",
    "    print df_concat.isnull().sum()\n",
    "    return df_concat\n",
    "\n",
    "def set_date_range(df, start_date, end_date):\n",
    "    lm(\"Set date range Dates\")\n",
    "    print start_date, end_date\n",
    "    # using a 15 year perriod\n",
    "    lm(\"Using aa 15 year period of data\")\n",
    "    df = df[start_date:end_date].copy()\n",
    "    print df.head()\n",
    "    return df\n",
    "    \n",
    "# df_raw = load_and_prepare_data()\n",
    "\n",
    "# start_date = '2001-01-04'\n",
    "# end_date = '2016-01-04'\n",
    "# df_train = set_date_range(df_raw, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_daily_ret(df):\n",
    "    lm(\"calculate daily returns\")\n",
    "    # calculate dailt returns\n",
    "    df_dr = (df / df.shift(1)) -1\n",
    "    df_dr.columns = [\"%s_%s\" % (col, 'dr') for col in df.columns]\n",
    "    df_dr.fillna(method='bfill', inplace=True)\n",
    "    return df_dr\n",
    "\n",
    "def calc_rolling_averages(df_in, windows):\n",
    "    lm(\"caluclate rolling averages\")\n",
    "    # caluclate rolling averages\n",
    "    def calc_rolling_mean(df_in, windows):\n",
    "        new_columns = []\n",
    "        for window in windows:\n",
    "            new_df = pd.rolling_mean(df_in, window)\n",
    "            new_df.columns = [\"%s_%s\" % (col, window) for col in new_df.columns]\n",
    "            new_df.fillna(method='bfill', inplace=True)\n",
    "            new_columns.append(new_df)\n",
    "\n",
    "        result = pd.concat(new_columns, axis=1)\n",
    "        return result\n",
    "\n",
    "    # Get rolling averages from daily returns\n",
    "    df_dr_rm = calc_rolling_mean(df_in, windows)\n",
    "    return df_dr_rm\n",
    "\n",
    "def draw_info(df_in, windows):\n",
    "    def draw_graphs(df_in, cols, windows=None):\n",
    "        if windows:\n",
    "            cols = ['%s_%s' % (col, window) for col in cols for window in windows]\n",
    "\n",
    "        print cols\n",
    "        df_in[cols].plot(figsize=(15, 5)).legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        plt.axhline(0)\n",
    "        plt.show()\n",
    "\n",
    "    lm(\"Draw a graph\")\n",
    "    draw_graphs(df_dr_rm, df_dr.columns, [180])\n",
    "    #draw_graphs(df_dr_rm, df_dr.columns, [30])\n",
    "\n",
    "    #df_all = pd.concat([df, df_dr, df_dr_rm], axis=1)\n",
    "\n",
    "# df_dr = calc_daily_ret(df_train)\n",
    "# windows = [2, 7, 30, 180]\n",
    "# df_rw = calc_rolling_averages(df_dr, windows)\n",
    "\n",
    "# df_y = create_y_labels(df_dr)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Kept here incase I need some of this later\n",
    "\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# import numpy as np\n",
    "\n",
    "# def rolling_linear_regression(df, n, col):\n",
    "#     def func(indexes, df): \n",
    "#         d_tmp = df.loc[indexes]\n",
    "                \n",
    "#         X = np.array(range(len(indexes))).reshape([-1, 1])\n",
    "#         y = d_tmp[col].reshape([-1, 1])\n",
    "        \n",
    "#         lr.fit(X, y)\n",
    "#         result = lr.coef_\n",
    "        \n",
    "#         return result\n",
    "    \n",
    "#     lr = LinearRegression()\n",
    "#     result = pd.rolling_apply(df.index.values, n, lambda i: func(i, df))\n",
    "#     return result\n",
    "\n",
    "# def rate_of_change(df, n, col):\n",
    "#     prev = df.shift(n)[col]\n",
    "#     result = 100 * (df[col] - prev) / prev\n",
    "#     return result\n",
    "\n",
    "# def roc_ratio(df, n, col):\n",
    "#     prev = df.shift(n)[col]\n",
    "    \n",
    "    \n",
    "# for n in [5, 10, 20]:\n",
    "#     df['lr_%s' % n] = rolling_linear_regression(df, n, 'v')\n",
    "#     df['roc_%s' % n] = rate_of_change(df, n, 'v')\n",
    "\n",
    "# df['v'].plot()\n",
    "# df[['lr_%s' % n for n in [5, 10, 20]]].plot()\n",
    "# df[['roc_%s' % n for n in [5, 10, 20]]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fookit, lets see is we can predict\n"
     ]
    }
   ],
   "source": [
    "lm('fookit, lets see is we can predict')\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def test_train(X_in, y_in, clf, param_grid, columns=None): \n",
    "    print X_in.shape\n",
    "    print y_in.shape\n",
    "    print X_in.columns.values\n",
    "\n",
    "    lm(\"Ensure no nulls in dataset\")\n",
    "    if X_in.isnull().any().any():\n",
    "        raise \"Empy values in dataset\"\n",
    "    \n",
    "    if columns:\n",
    "        print columns\n",
    "        X_in = X_in[columns]\n",
    "    print X_in.columns.values\n",
    "    \n",
    "    lm('split the data')\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X_in, y_in, test_size=0.3)\n",
    "\n",
    "    gs = GridSearchCV(clf, param_grid)\n",
    "    \n",
    "    print \"Training\"\n",
    "    gs.fit(X_in, y_in)\n",
    "    \n",
    "    print \"Trained\"\n",
    "    return gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_and_score(clf, X_test, y_test):\n",
    "    from sklearn.metrics import f1_score\n",
    "    lm('Lets see if it scores')\n",
    "    pred = clf.predict(X_test)\n",
    "\n",
    "    score = f1_score(y_test, pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets see how it works for the last year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data_ready():\n",
    "    df_raw = load_and_prepare_data()\n",
    "    start_date = '2001-01-04'\n",
    "    end_date = '2016-01-04'\n",
    "    df_train = set_date_range(df_raw, start_date, end_date)\n",
    "    df_dr = calc_daily_ret(df_train)\n",
    "    windows = [2, 7, 30, 180]\n",
    "    df_rw = calc_rolling_averages(df_dr, windows)\n",
    "    \n",
    "    df_y = create_y_labels(df_dr)\n",
    "    \n",
    "    df_X = pd.concat([df_dr, df_rw], axis=1)\n",
    "    return df_X, df_y\n",
    "\n",
    "\n",
    "def create_y_labels(df_all):\n",
    "    # Extract the labels vector\n",
    "    lm(\"Create the y labels vector\")\n",
    "    df_y = (df_all['GOLD_dr'].shift(-1) > 0) * 1.\n",
    "    return df_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Load currencies\n",
      "\n",
      "Loading file:currencies\n",
      "         DATE  FRED/DEXJPUS - VALUE  FRED/DEXUSAL - VALUE  \\\n",
      "0  1971-01-04                357.73                1.1127   \n",
      "1  1971-01-05                357.81                1.1132   \n",
      "2  1971-01-06                357.86                1.1140   \n",
      "3  1971-01-07                357.87                1.1138   \n",
      "4  1971-01-08                357.82                1.1124   \n",
      "\n",
      "   FRED/DEXUSUK - VALUE  FRED/DEXUSNZ - VALUE  FRED/DEXCHUS - VALUE  \\\n",
      "0                2.3938                1.1138                   NaN   \n",
      "1                2.3949                1.1143                   NaN   \n",
      "2                2.3967                1.1151                   NaN   \n",
      "3                2.3963                1.1150                   NaN   \n",
      "4                2.3972                1.1154                   NaN   \n",
      "\n",
      "   FRED/DEXCAUS - VALUE  FRED/DEXSZUS - VALUE  FRED/DEXUSEU - VALUE  \n",
      "0                1.0109                4.3180                   NaN  \n",
      "1                1.0102                4.3117                   NaN  \n",
      "2                1.0106                4.3113                   NaN  \n",
      "3                1.0148                4.3103                   NaN  \n",
      "4                1.0154                4.3109                   NaN  \n",
      "\n",
      "Are we using the correct timezone?\n",
      "\n",
      "inverse currencies so they are all 'how many x does 1 usd buy'\n",
      "DATE\n",
      "1971-01-04    0.417746\n",
      "1971-01-05    0.417554\n",
      "1971-01-06    0.417240\n",
      "1971-01-07    0.417310\n",
      "1971-01-08    0.417153\n",
      "1971-01-11    0.416806\n",
      "1971-01-12    0.416649\n",
      "1971-01-13    0.416302\n",
      "1971-01-14    0.415438\n",
      "1971-01-15    0.415679\n",
      "Name: GBP, dtype: float64\n",
      "\n",
      "Lets get the gold\n",
      "\n",
      "Loading file:LBMA_GOLD\n",
      "         Date  USD (AM)  USD (PM)  GBP (AM)  GBP (PM)  EURO (AM)  EURO (PM)\n",
      "0  1968-01-02     35.18       NaN    14.641       NaN        NaN        NaN\n",
      "1  1968-01-03     35.16       NaN    14.617       NaN        NaN        NaN\n",
      "2  1968-01-04     35.14       NaN    14.603       NaN        NaN        NaN\n",
      "3  1968-01-05     35.14       NaN    14.597       NaN        NaN        NaN\n",
      "4  1968-01-08     35.14       NaN    14.586       NaN        NaN        NaN\n",
      "\n",
      "Forward fill weekends and holidays\n",
      "GOLD     248\n",
      "JPY     1095\n",
      "AUD     1096\n",
      "GBP     1089\n",
      "NZD     1105\n",
      "CNY     3649\n",
      "CAD     1083\n",
      "CHF     1089\n",
      "EUR     8110\n",
      "dtype: int64\n",
      "GOLD       0\n",
      "JPY      753\n",
      "AUD      753\n",
      "GBP      753\n",
      "NZD      753\n",
      "CNY     3339\n",
      "CAD      753\n",
      "CHF      753\n",
      "EUR     7985\n",
      "dtype: int64\n",
      "\n",
      "Set date range Dates\n",
      "2001-01-04 2016-01-04\n",
      "\n",
      "Using aa 15 year period of data\n",
      "              GOLD       JPY       AUD       GBP       NZD       CNY  \\\n",
      "2001-01-04  268.75  0.008660  1.768347  0.669792  2.243662  0.120801   \n",
      "2001-01-05  268.00  0.008607  1.750700  0.667111  2.213369  0.120809   \n",
      "2001-01-08  268.60  0.008623  1.766784  0.668047  2.219756  0.120805   \n",
      "2001-01-09  267.75  0.008573  1.776830  0.671141  2.234637  0.120815   \n",
      "2001-01-10  266.70  0.008601  1.794688  0.670691  2.248707  0.120818   \n",
      "\n",
      "                 CAD       CHF       EUR  \n",
      "2001-01-04  0.667334  0.620540  1.058425  \n",
      "2001-01-05  0.666533  0.624025  1.048768  \n",
      "2001-01-08  0.669165  0.622045  1.054185  \n",
      "2001-01-09  0.667869  0.616903  1.064169  \n",
      "2001-01-10  0.666978  0.615195  1.065303  \n",
      "\n",
      "calculate daily returns\n",
      "\n",
      "caluclate rolling averages\n",
      "\n",
      "Create the y labels vector\n",
      "(2584, 45)\n",
      "(2584,)\n",
      "['GOLD_dr' 'JPY_dr' 'AUD_dr' 'GBP_dr' 'NZD_dr' 'CNY_dr' 'CAD_dr' 'CHF_dr'\n",
      " 'EUR_dr' 'GOLD_dr_2' 'JPY_dr_2' 'AUD_dr_2' 'GBP_dr_2' 'NZD_dr_2'\n",
      " 'CNY_dr_2' 'CAD_dr_2' 'CHF_dr_2' 'EUR_dr_2' 'GOLD_dr_7' 'JPY_dr_7'\n",
      " 'AUD_dr_7' 'GBP_dr_7' 'NZD_dr_7' 'CNY_dr_7' 'CAD_dr_7' 'CHF_dr_7'\n",
      " 'EUR_dr_7' 'GOLD_dr_30' 'JPY_dr_30' 'AUD_dr_30' 'GBP_dr_30' 'NZD_dr_30'\n",
      " 'CNY_dr_30' 'CAD_dr_30' 'CHF_dr_30' 'EUR_dr_30' 'GOLD_dr_180' 'JPY_dr_180'\n",
      " 'AUD_dr_180' 'GBP_dr_180' 'NZD_dr_180' 'CNY_dr_180' 'CAD_dr_180'\n",
      " 'CHF_dr_180' 'EUR_dr_180']\n",
      "\n",
      "Ensure no nulls in dataset\n",
      "['GOLD_dr' 'JPY_dr' 'AUD_dr' 'GBP_dr' 'NZD_dr' 'CNY_dr' 'CAD_dr' 'CHF_dr'\n",
      " 'EUR_dr' 'GOLD_dr_2' 'JPY_dr_2' 'AUD_dr_2' 'GBP_dr_2' 'NZD_dr_2'\n",
      " 'CNY_dr_2' 'CAD_dr_2' 'CHF_dr_2' 'EUR_dr_2' 'GOLD_dr_7' 'JPY_dr_7'\n",
      " 'AUD_dr_7' 'GBP_dr_7' 'NZD_dr_7' 'CNY_dr_7' 'CAD_dr_7' 'CHF_dr_7'\n",
      " 'EUR_dr_7' 'GOLD_dr_30' 'JPY_dr_30' 'AUD_dr_30' 'GBP_dr_30' 'NZD_dr_30'\n",
      " 'CNY_dr_30' 'CAD_dr_30' 'CHF_dr_30' 'EUR_dr_30' 'GOLD_dr_180' 'JPY_dr_180'\n",
      " 'AUD_dr_180' 'GBP_dr_180' 'NZD_dr_180' 'CNY_dr_180' 'CAD_dr_180'\n",
      " 'CHF_dr_180' 'EUR_dr_180']\n",
      "\n",
      "split the data\n",
      "Training\n",
      "Trained\n",
      "Actual\n",
      "\n",
      "Lets see if it scores\n",
      "0.649921507064\n",
      "random sample\n",
      "0.504025764895\n"
     ]
    }
   ],
   "source": [
    "def run(train_start, train_end, test_start, test_end):\n",
    "    X, y = get_data_ready()\n",
    "\n",
    "    # Get data for training\n",
    "    X_train = X[train_start: train_end]\n",
    "    y_train = y[train_start: train_end]\n",
    "\n",
    "    param_grid={\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "    }\n",
    "    clf = SVC()\n",
    "    best_clf = test_train(X_train, y_train, clf, param_grid)\n",
    "\n",
    "    # Get data for testing\n",
    "    X_test = X[test_start: test_end]\n",
    "    y_test = y[test_start: test_end]\n",
    "    \n",
    "    print \"Actual\"\n",
    "    print predict_and_score(best_clf, X_test, y_test)\n",
    "    \n",
    "    print \"random sample\"\n",
    "    pred_sample = y_test.sample(y_test.shape[0])\n",
    "    from sklearn.metrics import f1_score\n",
    "    print f1_score(y_test, pred_sample)\n",
    "    \n",
    "data_start = '2001-01-04'\n",
    "data_end = '2016-01-04'\n",
    "#run('2001-01-04', '2014-01-04', '2014-01-04', '2016-01-04')\n",
    "#run('2011-01-04', '2016-01-04', '2001-01-04', '2006-01-04')\n",
    "run('2001-01-04', '2011-01-04', '2011-01-04', '2016-01-04')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
