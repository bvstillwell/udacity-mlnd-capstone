{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progress Steps\n",
    "* So are we going to be rich?\n",
    "* What is a cross currency?\n",
    "* Are the times correct for gold?\n",
    "* Where do I get the data?\n",
    "\n",
    "* What makes a good prediction?\n",
    " * Tomorrows prediction?\n",
    " * A few days out?\n",
    " * Binary or multiclass?\n",
    " * Scoring, Accuracy v precision\n",
    " \n",
    "* Results\n",
    " * Prediction over 1 year\n",
    " * Predict days in the future [1, 7, 30, 90]\n",
    " * Predict k vs one\n",
    "\n",
    "* Training data\n",
    "    * Previous [10y, 5y, 2y, 1y, 6m]\n",
    "    * Retraining\n",
    "    \n",
    "* Retraining\n",
    " * How does retrianing affect the result?\n",
    " * Which windows to use?\n",
    " \n",
    "* Feature selection\n",
    "1. Daily rates\n",
    "    1. 5, 30 and 90 day windows\n",
    "\n",
    "* Comparing classifiers\n",
    " * Decision tree\n",
    " * SVM\n",
    " * Logistic regression\n",
    " * NN\n",
    " * Ada boost\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just remember.... Start with the simplist model, and add features\n",
    "## Features\n",
    "- Daily returns\n",
    " - daily_returns[t] = (price[t]/price[-1])-1\n",
    "\n",
    "## Predictions\n",
    "1. Will the price stay the same or go up tomorrow. up=1, others=0\n",
    "\n",
    "## Things I want to find out\n",
    "- Can we predict gold resonably well\n",
    "    - What features are corrrelated?\n",
    "    - What are good features?\n",
    "    - Do we need lots of them?\n",
    "- Has trading changed in modern times\n",
    "    - Has automated trading made things different?\n",
    "    - Do we overfit if we only look at old data?\n",
    "    - Was old data correlated to different features that are no longer important?\n",
    "       \n",
    "## New quesitions\n",
    "- Do the dates work correctly?\n",
    " - Asuming the day is correct, we use\n",
    " - UK Gold 10:30am (GMT)\n",
    " - UK Gold 3pm (GMT)\n",
    " - FX NYC 12pm (4pm GMT)\n",
    "  - http://www.federalreserve.gov/pubs/bulletin/2005/winter05_index.pdf\n",
    "\n",
    "- Score seems kind of high, why?\n",
    "    - LogarythmicRegression not working\n",
    " \n",
    "- Is the model accurate today?\n",
    "    - Let's test on the data from the last year\n",
    "\n",
    "- How long is a model valid before it's predictions don't work?\n",
    "\n",
    "- Can the model predict further out?\n",
    "\n",
    "- Are they correct if we retrain every day?\n",
    "\n",
    "- Can we predict bigger changes rather than just positive?\n",
    "\n",
    "- What is most important? Acucracy, recall, both?\n",
    "\n",
    "## Notes discovered\n",
    "We are only predicting gold against USD. What about the global economy? Do we use a bag of currencies? What are their weightings?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:LOADING Helper1 :-)2016-05-29 16:54:00.639856\n",
      "INFO:root:fookit, lets see is we can predict\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['KFold',\n",
       " '__builtins__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " 'calc_daily_ret',\n",
       " 'calc_rolling_averages',\n",
       " 'create_y_labels',\n",
       " 'currencies',\n",
       " 'datetime',\n",
       " 'download_quandl',\n",
       " 'draw_info',\n",
       " 'grid_search',\n",
       " 'ld',\n",
       " 'li',\n",
       " 'load_and_calculate',\n",
       " 'load_and_prepare_data',\n",
       " 'logger',\n",
       " 'logging',\n",
       " 'os',\n",
       " 'pd',\n",
       " 'plt',\n",
       " 'quandl',\n",
       " 're',\n",
       " 'set_date_range',\n",
       " 'test',\n",
       " 'test_train',\n",
       " 'train']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import helper1 as hlp\n",
    "dir(hlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Kept here incase I need some of this later\n",
    "\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# import numpy as np\n",
    "\n",
    "# def rolling_linear_regression(df, n, col):\n",
    "#     def func(indexes, df): \n",
    "#         d_tmp = df.loc[indexes]\n",
    "                \n",
    "#         X = np.array(range(len(indexes))).reshape([-1, 1])\n",
    "#         y = d_tmp[col].reshape([-1, 1])\n",
    "        \n",
    "#         lr.fit(X, y)\n",
    "#         result = lr.coef_\n",
    "        \n",
    "#         return result\n",
    "    \n",
    "#     lr = LinearRegression()\n",
    "#     result = pd.rolling_apply(df.index.values, n, lambda i: func(i, df))\n",
    "#     return result\n",
    "\n",
    "# def rate_of_change(df, n, col):\n",
    "#     prev = df.shift(n)[col]\n",
    "#     result = 100 * (df[col] - prev) / prev\n",
    "#     return result\n",
    "\n",
    "# def roc_ratio(df, n, col):\n",
    "#     prev = df.shift(n)[col]\n",
    "    \n",
    "    \n",
    "# for n in [5, 10, 20]:\n",
    "#     df['lr_%s' % n] = rolling_linear_regression(df, n, 'v')\n",
    "#     df['roc_%s' % n] = rate_of_change(df, n, 'v')\n",
    "\n",
    "# df['v'].plot()\n",
    "# df[['lr_%s' % n for n in [5, 10, 20]]].plot()\n",
    "# df[['roc_%s' % n for n in [5, 10, 20]]].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets see how it works for the last year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:LOADING Helper1 :-)2016-05-29 17:09:04.241606\n",
      "INFO:root:fookit, lets see is we can predict\n",
      "INFO:root:Load currencies\n",
      "INFO:root:Loading file:currencies\n",
      "INFO:root:Are we using the correct timezone?\n",
      "INFO:root:inverse currencies so they are all 'how many x does 1 usd buy'\n",
      "INFO:root:Lets get the gold\n",
      "INFO:root:Loading file:LBMA_GOLD\n",
      "INFO:root:Forward fill weekends and holidays\n",
      "INFO:root:Set date range Dates\n",
      "INFO:root:Using aa 15 year period of data\n",
      "INFO:root:calculate daily returns\n",
      "INFO:root:caluclate rolling averages\n",
      "INFO:root:Index([u'GOLD_dr', u'JPY_dr', u'AUD_dr', u'GBP_dr', u'NZD_dr', u'CNY_dr',\n",
      "       u'CAD_dr', u'CHF_dr', u'EUR_dr', u'GOLD_dr_2', u'JPY_dr_2', u'AUD_dr_2',\n",
      "       u'GBP_dr_2', u'NZD_dr_2', u'CNY_dr_2', u'CAD_dr_2', u'CHF_dr_2',\n",
      "       u'EUR_dr_2', u'GOLD_dr_7', u'JPY_dr_7', u'AUD_dr_7', u'GBP_dr_7',\n",
      "       u'NZD_dr_7', u'CNY_dr_7', u'CAD_dr_7', u'CHF_dr_7', u'EUR_dr_7',\n",
      "       u'GOLD_dr_30', u'JPY_dr_30', u'AUD_dr_30', u'GBP_dr_30', u'NZD_dr_30',\n",
      "       u'CNY_dr_30', u'CAD_dr_30', u'CHF_dr_30', u'EUR_dr_30', u'GOLD_dr_180',\n",
      "       u'JPY_dr_180', u'AUD_dr_180', u'GBP_dr_180', u'NZD_dr_180',\n",
      "       u'CNY_dr_180', u'CAD_dr_180', u'CHF_dr_180', u'EUR_dr_180'],\n",
      "      dtype='object')\n",
      "INFO:root:Create the y labels vector\n",
      "INFO:root:Actual\n",
      "INFO:root:             precision    recall  f1-score   support\n",
      "\n",
      "          D       0.49      0.70      0.58        63\n",
      "          U       0.70      0.49      0.58        91\n",
      "\n",
      "avg / total       0.62      0.58      0.58       154\n",
      "\n",
      "INFO:root:random sample\n",
      "INFO:root:             precision    recall  f1-score   support\n",
      "\n",
      "          D       0.43      0.43      0.43        63\n",
      "          U       0.60      0.60      0.60        91\n",
      "\n",
      "avg / total       0.53      0.53      0.53       154\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "pos_label=1 is not a valid label: array(['D', 'U'], \n      dtype='|S1')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-3e08bcbe0d3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m }\n\u001b[0;32m     33\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0mtrain_and_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'2001-04-01'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'2015-06-01'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'2015-06-01'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'2016-09-01'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-3e08bcbe0d3e>\u001b[0m in \u001b[0;36mtrain_and_test\u001b[1;34m(clf, X, y, train_start, train_end, test_start, test_end, param_grid)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_start\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtest_end\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_start\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtest_end\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/brad/github/udacity/p5/r1/helper1.py\u001b[0m in \u001b[0;36mtest\u001b[1;34m(clf, X_test, y_test)\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_actual\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/brad/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[0;32m    637\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[0;32m    638\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 639\u001b[1;33m                        sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/brad/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[0;32m    754\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'f-score'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 756\u001b[1;33m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    757\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/brad/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[0;32m    982\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    983\u001b[0m                     raise ValueError(\"pos_label=%r is not a valid label: %r\" %\n\u001b[1;32m--> 984\u001b[1;33m                                      (pos_label, present_labels))\n\u001b[0m\u001b[0;32m    985\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    986\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: pos_label=1 is not a valid label: array(['D', 'U'], \n      dtype='|S1')"
     ]
    }
   ],
   "source": [
    "def train_and_test(clf, X, y, train_start, train_end, test_start, test_end, param_grid=None):\n",
    "    # Get data for training\n",
    "    X_train = X[train_start: train_end]\n",
    "    y_train = y[train_start: train_end]\n",
    "\n",
    "    clf = hlp.train(clf,X_train, y_train, param_grid)\n",
    "    \n",
    "    \n",
    "    X_test = X[test_start: test_end]\n",
    "    y_test = y[test_start: test_end]\n",
    "    score = hlp.test(clf, X_test, y_test)\n",
    "    return score\n",
    "    \n",
    "\n",
    "X = hlp.load_and_calculate()\n",
    "hlp.li(X.columns)\n",
    "y = hlp.create_y_labels(X['GOLD_dr'], days_ahead=1, threshold=0.0002)\n",
    "y = y.map({1.0:'U', 2.0:'D'})\n",
    "\n",
    "import pandas as pd\n",
    "#print pd.concat([X['GOLD_dr'], X['GOLD_dr'].shift(1), X['GOLD_dr'].shift(2)], axis=1)\n",
    "\n",
    "cols = X.columns.values\n",
    "for col in cols:\n",
    "    if \"GOLD_\" in col:\n",
    "        X.drop(col, axis=1, inplace=True)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "param_grid={\n",
    "    'max_depth': range(2,5) + [10, 15],\n",
    "    'min_samples_split' : [2,10,20]\n",
    "}\n",
    "clf = DecisionTreeClassifier()\n",
    "train_and_test(clf, X, y, '2001-04-01', '2015-06-01','2015-06-01', '2016-09-01', param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:1\n",
      "INFO:root:Create the y labels vector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3101, 45)\n",
      "(3101,)\n",
      "2    1604\n",
      "1    1497\n",
      "Name: GOLD_dr, dtype: int64\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Actual\n",
      "INFO:root:0.490106544901\n",
      "INFO:root:             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.60      0.41      0.49       390\n",
      "        2.0       0.48      0.67      0.56       321\n",
      "\n",
      "avg / total       0.55      0.53      0.52       711\n",
      "\n",
      "INFO:root:random sample\n",
      "INFO:root:0.551282051282\n",
      "INFO:root:2\n",
      "INFO:root:Create the y labels vector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(array([ 1.,  2.]), array([267, 444]))\n",
      "(3101, 45)\n",
      "(3101,)\n",
      "2    1604\n",
      "1    1497\n",
      "Name: GOLD_dr, dtype: int64\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Actual\n",
      "INFO:root:0.383045525903\n",
      "INFO:root:             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.49      0.31      0.38       390\n",
      "        2.0       0.42      0.61      0.50       321\n",
      "\n",
      "avg / total       0.46      0.45      0.44       711\n",
      "\n",
      "INFO:root:random sample\n",
      "INFO:root:0.54358974359\n",
      "INFO:root:30\n",
      "INFO:root:Create the y labels vector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(array([ 1.,  2.]), array([247, 464]))\n",
      "(3101, 45)\n",
      "(3101,)\n",
      "2    1603\n",
      "1    1498\n",
      "Name: GOLD_dr, dtype: int64\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=10, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Actual\n",
      "INFO:root:0.574233128834\n",
      "INFO:root:             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.57      0.58      0.57       404\n",
      "        2.0       0.43      0.42      0.43       307\n",
      "\n",
      "avg / total       0.51      0.51      0.51       711\n",
      "\n",
      "INFO:root:random sample\n",
      "INFO:root:0.596534653465\n",
      "INFO:root:60\n",
      "INFO:root:Create the y labels vector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(array([ 1.,  2.]), array([411, 300]))\n",
      "(3101, 45)\n",
      "(3101,)\n",
      "2    1601\n",
      "1    1500\n",
      "Name: GOLD_dr, dtype: int64\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Actual\n",
      "INFO:root:0.633684210526\n",
      "INFO:root:             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.56      0.72      0.63       417\n",
      "        2.0       0.35      0.21      0.26       294\n",
      "\n",
      "avg / total       0.48      0.51      0.48       711\n",
      "\n",
      "INFO:root:random sample\n",
      "INFO:root:0.592326139089\n",
      "INFO:root:90\n",
      "INFO:root:Create the y labels vector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(array([ 1.,  2.]), array([533, 178]))\n",
      "(3101, 45)\n",
      "(3101,)\n",
      "2    1605\n",
      "1    1496\n",
      "Name: GOLD_dr, dtype: int64\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=15,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Actual\n",
      "INFO:root:0.490984743412\n",
      "INFO:root:             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.62      0.41      0.49       435\n",
      "        2.0       0.39      0.61      0.48       276\n",
      "\n",
      "avg / total       0.53      0.48      0.49       711\n",
      "\n",
      "INFO:root:random sample\n",
      "INFO:root:0.602298850575\n",
      "INFO:root:180\n",
      "INFO:root:Create the y labels vector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(array([ 1.,  2.]), array([286, 425]))\n",
      "(3101, 45)\n",
      "(3101,)\n",
      "2    1598\n",
      "1    1503\n",
      "Name: GOLD_dr, dtype: int64\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Actual\n",
      "INFO:root:0.0369609856263\n",
      "INFO:root:             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.56      0.02      0.04       471\n",
      "        2.0       0.34      0.97      0.50       240\n",
      "\n",
      "avg / total       0.49      0.34      0.19       711\n",
      "\n",
      "INFO:root:random sample\n",
      "INFO:root:0.632696390658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(array([ 1.,  2.]), array([ 16, 695]))\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i in [1, 2, 30, 60, 90, 180]:\n",
    "    hlp.li(i)\n",
    "    y = hlp.create_y_labels(X['GOLD_dr'], days_ahead=i)\n",
    "    score = run(X, y, '2001-04-01', '2013-04-01','2013-04-01', '2016-04-01')\n",
    "    scores.append(score)\n",
    "\n",
    "# for c in [1, 5, 30, 60]\n",
    "#     y = hlp.create_y_labels(X['GOLD_dr'])\n",
    "#     run(X, y, '2001-01-04', '2011-01-04', '2011-01-04', '2016-01-04')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.49010654490106542,\n",
       " 0.38304552590266872,\n",
       " 0.57423312883435573,\n",
       " 0.63368421052631574,\n",
       " 0.49098474341192783,\n",
       " 0.036960985626283367]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEDCAYAAAAoWo9tAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3857e2b290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "import seaborn as sns\n",
    "sns.barplot(x=range(len(scores)), y=scores)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
