{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just remember.... Start with the simplist model, and add features\n",
    "## Features\n",
    "- Daily returns\n",
    " - daily_returns[t] = (price[t]/price[-1])-1\n",
    "\n",
    "## Predictions\n",
    "1. Will the price stay the same or go up tomorrow. up=1, others=0\n",
    "\n",
    "## Things I want to find out\n",
    "- Can we predict gold resonably well\n",
    "    - What features are corrrelated?\n",
    "    - What are good features?\n",
    "    - Do we need lots of them?\n",
    "- Has trading changed in modern times\n",
    "    - Has automated trading made things different?\n",
    "    - Do we overfit if we only look at old data?\n",
    "    - Was old data correlated to different features that are no longer important?\n",
    "       \n",
    "## New quesitions\n",
    "- Do the dates work correctly?\n",
    " - Asuming the day is correct, we use\n",
    " - UK Gold 10:30am (GMT)\n",
    " - UK Gold 3pm (GMT)\n",
    " - FX NYC 12pm (4pm GMT)\n",
    "  - http://www.federalreserve.gov/pubs/bulletin/2005/winter05_index.pdf\n",
    "\n",
    "- Score seems kind of high, why?\n",
    "- Is the model accurate today?\n",
    "    - Let's test on the data from the last year\n",
    "\n",
    "- How long is a model valid before it's predictions don't work?\n",
    "\n",
    "- Can the model predict further out?\n",
    "\n",
    "- Are they correct if we retrain every day?\n",
    "\n",
    "- Can we predict bigger changes rather than just positive?\n",
    "\n",
    "## Notes discovered\n",
    "We are only predicting gold against USD. What about the global economy? Do we use a bag of currencies? What are their weightings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Log message\n",
    "def lm(text):\n",
    "    logging.info(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import quandl\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logging.debug(\"test\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# import quandl\n",
    "def download_quandl(codes, filename=None, load_file=True):\n",
    "    if filename is None:\n",
    "        filename = re.sub('[^-a-zA-Z0-9_.() ]+', '_', codes)\n",
    "\n",
    "    if load_file and os.path.exists(filename):\n",
    "        lm(\"Loading file:%s\" % filename)\n",
    "        return pd.read_csv(filename)\n",
    "    \n",
    "    the_data = quandl.get(codes)\n",
    "    the_data.describe()\n",
    "    the_data.head()\n",
    "    the_data.to_csv(filename)\n",
    "    return the_data\n",
    "\n",
    "currencies = {\n",
    "#     'AUD': 'FRED/XUDLADD', \n",
    "#     'JPY': 'FRED/XUDLJYD',\n",
    "#     'GBP': 'FRED/XUDLGBD',\n",
    "#     #'EUR': 'FRED/DEXUSEU',\n",
    "#     'EUR': 'FRED/XUDLERG',\n",
    "#     'CAD': 'FRED/XUDLCDD',\n",
    "#     'CHF': 'FRED/XUDLSFD',\n",
    "#     'CNY': 'FRED/XUDLBK73',\n",
    "#     'NZD': 'FRED/XUDLNDD',\n",
    "    \n",
    "    'AUD': 'FRED/DEXUSAL', \n",
    "    'JPY': 'FRED/DEXJPUS',\n",
    "    'GBP': 'FRED/DEXUSUK',\n",
    "    'EUR': 'FRED/DEXUSEU',\n",
    "    'CAD': 'FRED/DEXCAUS',\n",
    "    'CHF': 'FRED/DEXSZUS',\n",
    "    'CNY': 'FRED/DEXCHUS',\n",
    "    'NZD': 'FRED/DEXUSNZ',\n",
    "    }\n",
    "\n",
    "def load_and_prepare_data():\n",
    "    lm(\"Load currencies\")\n",
    "    df_curr = download_quandl([currencies[k] for k in currencies], 'currencies')\n",
    "    logging.debug(df_curr.head())\n",
    "    #df_curr.describe()\n",
    "    df_curr.set_index('DATE', inplace=True)\n",
    "    df_curr.columns = [a for a in currencies]\n",
    "\n",
    "    lm(\"Are we using the correct timezone?\")\n",
    "    #FRED = noon NYC time\n",
    "    # London 10:30,3pm\n",
    "    # NYC \n",
    "\n",
    "\n",
    "\n",
    "    lm(\"inverse currencies so they are all 'how many x does 1 usd buy'\")\n",
    "    for curr in currencies:\n",
    "        if currencies[curr][:-2] != 'US':\n",
    "            df_curr[curr] = 1. / df_curr[curr]\n",
    "    logging.debug(df_curr['GBP'][:10])\n",
    "\n",
    "    lm(\"Lets get the gold\")\n",
    "    df_gold = download_quandl(\"LBMA/GOLD\")\n",
    "    logging.debug(df_gold.head())\n",
    "    df_gold.set_index('Date', inplace=True)\n",
    "    pd.concat([df_gold, df_curr], axis=1)\n",
    "    df_gold.drop([c for c in df_gold.columns.values if c != 'USD (AM)'], axis=1, inplace=True)\n",
    "    df_gold.columns = ['GOLD']\n",
    "\n",
    "    df_concat = pd.concat([df_gold, df_curr], axis=1)\n",
    "\n",
    "    lm(\"Forward fill weekends and holidays\")\n",
    "    logging.debug( df_concat.isnull().sum())\n",
    "    df_concat.fillna(method='ffill', inplace=True)\n",
    "    logging.debug(df_concat.isnull().sum())\n",
    "    return df_concat\n",
    "\n",
    "def set_date_range(df, start_date, end_date):\n",
    "    lm(\"Set date range Dates\")\n",
    "    logging.debug(start_date, end_date)\n",
    "    # using a 15 year perriod\n",
    "    lm(\"Using aa 15 year period of data\")\n",
    "    df = df[start_date:end_date].copy()\n",
    "    logging.debug(df.head())\n",
    "    return df\n",
    "    \n",
    "# df_raw = load_and_prepare_data()\n",
    "\n",
    "# start_date = '2001-01-04'\n",
    "# end_date = '2016-01-04'\n",
    "# df_train = set_date_range(df_raw, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_daily_ret(df):\n",
    "    lm(\"calculate daily returns\")\n",
    "    # calculate dailt returns\n",
    "    df_dr = (df / df.shift(1)) -1\n",
    "    df_dr.columns = [\"%s_%s\" % (col, 'dr') for col in df.columns]\n",
    "    df_dr.fillna(method='bfill', inplace=True)\n",
    "    return df_dr\n",
    "\n",
    "def calc_rolling_averages(df_in, windows):\n",
    "    lm(\"caluclate rolling averages\")\n",
    "    # caluclate rolling averages\n",
    "    def calc_rolling_mean(df_in, windows):\n",
    "        new_columns = []\n",
    "        for window in windows:\n",
    "            new_df = pd.rolling_mean(df_in, window)\n",
    "            new_df.columns = [\"%s_%s\" % (col, window) for col in new_df.columns]\n",
    "            new_df.fillna(method='bfill', inplace=True)\n",
    "            new_columns.append(new_df)\n",
    "\n",
    "        result = pd.concat(new_columns, axis=1)\n",
    "        return result\n",
    "\n",
    "    # Get rolling averages from daily returns\n",
    "    df_dr_rm = calc_rolling_mean(df_in, windows)\n",
    "    return df_dr_rm\n",
    "\n",
    "def draw_info(df_in, windows):\n",
    "    def draw_graphs(df_in, cols, windows=None):\n",
    "        if windows:\n",
    "            cols = ['%s_%s' % (col, window) for col in cols for window in windows]\n",
    "\n",
    "        logging.debug(cols)\n",
    "        df_in[cols].plot(figsize=(15, 5)).legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        plt.axhline(0)\n",
    "        plt.show()\n",
    "\n",
    "    lm(\"Draw a graph\")\n",
    "    draw_graphs(df_dr_rm, df_dr.columns, [180])\n",
    "    #draw_graphs(df_dr_rm, df_dr.columns, [30])\n",
    "\n",
    "    #df_all = pd.concat([df, df_dr, df_dr_rm], axis=1)\n",
    "\n",
    "# df_dr = calc_daily_ret(df_train)\n",
    "# windows = [2, 7, 30, 180]\n",
    "# df_rw = calc_rolling_averages(df_dr, windows)\n",
    "\n",
    "# df_y = create_y_labels(df_dr)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Kept here incase I need some of this later\n",
    "\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# import numpy as np\n",
    "\n",
    "# def rolling_linear_regression(df, n, col):\n",
    "#     def func(indexes, df): \n",
    "#         d_tmp = df.loc[indexes]\n",
    "                \n",
    "#         X = np.array(range(len(indexes))).reshape([-1, 1])\n",
    "#         y = d_tmp[col].reshape([-1, 1])\n",
    "        \n",
    "#         lr.fit(X, y)\n",
    "#         result = lr.coef_\n",
    "        \n",
    "#         return result\n",
    "    \n",
    "#     lr = LinearRegression()\n",
    "#     result = pd.rolling_apply(df.index.values, n, lambda i: func(i, df))\n",
    "#     return result\n",
    "\n",
    "# def rate_of_change(df, n, col):\n",
    "#     prev = df.shift(n)[col]\n",
    "#     result = 100 * (df[col] - prev) / prev\n",
    "#     return result\n",
    "\n",
    "# def roc_ratio(df, n, col):\n",
    "#     prev = df.shift(n)[col]\n",
    "    \n",
    "    \n",
    "# for n in [5, 10, 20]:\n",
    "#     df['lr_%s' % n] = rolling_linear_regression(df, n, 'v')\n",
    "#     df['roc_%s' % n] = rate_of_change(df, n, 'v')\n",
    "\n",
    "# df['v'].plot()\n",
    "# df[['lr_%s' % n for n in [5, 10, 20]]].plot()\n",
    "# df[['roc_%s' % n for n in [5, 10, 20]]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:fookit, lets see is we can predict\n"
     ]
    }
   ],
   "source": [
    "lm('fookit, lets see is we can predict')\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def test_train(X_in, y_in, clf, param_grid, columns=None): \n",
    "    logging.debug( X_in.shape)\n",
    "    logging.debug(y_in.shape)\n",
    "    logging.debug(X_in.columns.values)\n",
    "\n",
    "    lm(\"Ensure no nulls in dataset\")\n",
    "    if X_in.isnull().any().any():\n",
    "        raise \"Empy values in dataset\"\n",
    "    \n",
    "    if columns:\n",
    "        logging.debug(columns)\n",
    "        X_in = X_in[columns]\n",
    "    logging.debug(X_in.columns.values)\n",
    "    \n",
    "    lm('split the data')\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X_in, y_in, test_size=0.3)\n",
    "\n",
    "    gs = GridSearchCV(clf, param_grid)\n",
    "    \n",
    "    logging.debug(\"Training\")\n",
    "    gs.fit(X_in, y_in)\n",
    "    \n",
    "    logging.debug(\"Trained\")\n",
    "    return gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_and_score(clf, X_test, y_test):\n",
    "    from sklearn.metrics import f1_score\n",
    "    lm('Lets see if it scores')\n",
    "    pred = clf.predict(X_test)\n",
    "\n",
    "    score = f1_score(y_test, pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets see how it works for the last year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_and_calculate():\n",
    "    df_raw = load_and_prepare_data()\n",
    "    start_date = '2001-01-04'\n",
    "    end_date = '2016-01-04'\n",
    "    df_train = set_date_range(df_raw, start_date, end_date)\n",
    "    df_dr = calc_daily_ret(df_train)\n",
    "    windows = [2, 7, 30, 180]\n",
    "    df_rw = calc_rolling_averages(df_dr, windows)\n",
    "    \n",
    "    df_X = pd.concat([df_dr, df_rw], axis=1)\n",
    "    return df_X\n",
    "\n",
    "def create_y_labels(df_in, days_ahead=1, threshold=0.):\n",
    "    # Extract the labels vector\n",
    "    lm(\"Create the y labels vector\")\n",
    "    df_y = (df_in.shift(-days_ahead) > threshold) * 1.\n",
    "    return df_y\n",
    "\n",
    "def get_data_ready():   \n",
    "    df_X = load_and_calculate()\n",
    "    df_y = create_y_labels(df_X['GOLD_dr'])\n",
    "    return df_X, df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Load currencies\n",
      "INFO:root:Loading file:currencies\n",
      "INFO:root:Are we using the correct timezone?\n",
      "INFO:root:inverse currencies so they are all 'how many x does 1 usd buy'\n",
      "INFO:root:Lets get the gold\n",
      "INFO:root:Loading file:LBMA_GOLD\n",
      "INFO:root:Forward fill weekends and holidays\n",
      "INFO:root:Set date range Dates\n",
      "INFO:root:Using aa 15 year period of data\n",
      "INFO:root:calculate daily returns\n",
      "INFO:root:caluclate rolling averages\n",
      "INFO:root:Create the y labels vector\n",
      "INFO:root:Ensure no nulls in dataset\n",
      "INFO:root:split the data\n",
      "INFO:root:Actual\n",
      "INFO:root:Lets see if it scores\n",
      "INFO:root:0.649921507064\n",
      "INFO:root:random sample\n",
      "INFO:root:0.48309178744\n"
     ]
    }
   ],
   "source": [
    "def run(train_start, train_end, test_start, test_end):\n",
    "    X, y = get_data_ready()\n",
    "\n",
    "    # Get data for training\n",
    "    X_train = X[train_start: train_end]\n",
    "    y_train = y[train_start: train_end]\n",
    "\n",
    "    param_grid={\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "    }\n",
    "    clf = SVC()\n",
    "    best_clf = test_train(X_train, y_train, clf, param_grid)\n",
    "\n",
    "    # Get data for testing\n",
    "    X_test = X[test_start: test_end]\n",
    "    y_test = y[test_start: test_end]\n",
    "    \n",
    "    logging.info(\"Actual\")\n",
    "    logging.info(predict_and_score(best_clf, X_test, y_test))\n",
    "    \n",
    "    logging.info(\"random sample\")\n",
    "    pred_sample = y_test.sample(y_test.shape[0])\n",
    "    from sklearn.metrics import f1_score\n",
    "    logging.info(f1_score(y_test, pred_sample))\n",
    "    \n",
    "data_start = '2001-01-04'\n",
    "data_end = '2016-01-04'\n",
    "#run('2001-01-04', '2014-01-04', '2014-01-04', '2016-01-04')\n",
    "#run('2011-01-04', '2016-01-04', '2001-01-04', '2006-01-04')\n",
    "run('2001-01-04', '2011-01-04', '2011-01-04', '2016-01-04')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Can we predict further out?\n",
    "For this we will try to predict from the rolling averages in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def run_further_out(train_start, train_end, test_start, test_end):    \n",
    "    df_y = create_y_labels(df_dr)\n",
    "    \n",
    "    \n",
    "    return df_X, df_y\n",
    "\n",
    "\n",
    "        \n",
    "    # Get data for training\n",
    "    X_train = X[train_start: train_end]\n",
    "    y_train = y[train_start: train_end]\n",
    "\n",
    "    param_grid={\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "    }\n",
    "    clf = SVC()\n",
    "    best_clf = test_train(X_train, y_train, clf, param_grid)\n",
    "\n",
    "    # Get data for testing\n",
    "    X_test = X[test_start: test_end]\n",
    "    y_test = y[test_start: test_end]\n",
    "    \n",
    "    logging.debug(\"Actual\")\n",
    "    logging.debug(predict_and_score(best_clf, X_test, y_test))\n",
    "    \n",
    "    logging.debug(\"random sample\")\n",
    "    pred_sample = y_test.sample(y_test.shape[0])\n",
    "    from sklearn.metrics import f1_score\n",
    "    logging.debug(f1_score(y_test, pred_sample))\n",
    "    \n",
    "data_start = '2001-01-04'\n",
    "data_end = '2016-01-04'\n",
    "#run('2001-01-04', '2014-01-04', '2014-01-04', '2016-01-04')\n",
    "#run('2011-01-04', '2016-01-04', '2001-01-04', '2006-01-04')\n",
    "run('2001-01-04', '2014-01-04', '2014-01-04', '2016-01-04')\n",
    "\n",
    "draw_info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
